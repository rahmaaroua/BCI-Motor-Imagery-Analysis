{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 03: Feature Extraction for Motor Imagery Classification\n",
    "\n",
    "## BCI Competition IV Dataset 2a - Motor Imagery Classification\n",
    "\n",
    "**Author:** Rahma Aroua\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Notebook Overview\n",
    "\n",
    "This notebook implements a comprehensive feature extraction pipeline for motor imagery EEG classification. Feature extraction is the **critical step** that transforms preprocessed EEG signals into discriminative representations for classification.\n",
    "\n",
    "**Feature Extraction Methods:**\n",
    "1. **Common Spatial Patterns (CSP)** â†’ Spatial filtering to maximize class separability\n",
    "2. **Band Power Features** â†’ Spectral power in mu (8-12 Hz) and beta (13-30 Hz) bands\n",
    "3. **Hjorth Parameters** â†’ Time-domain activity, mobility, and complexity\n",
    "4. **Statistical Features** â†’ Mean, standard deviation, skewness, kurtosis\n",
    "\n",
    "**Visualization & Analysis:**\n",
    "- CSP spatial patterns (topographic maps)\n",
    "- Feature importance ranking (mutual information)\n",
    "- ERD/ERS time-frequency maps\n",
    "- Feature distribution analysis\n",
    "\n",
    "**Dataset Context:**\n",
    "- **Input:** Preprocessed epochs from Notebook 02\n",
    "- **Output:** Feature matrix ready for classification\n",
    "- **Features:** 264 total features per trial\n",
    "  - CSP: 24 features (6 components Ã— 4 classes OVR)\n",
    "  - Band Power: 88 features (22 channels Ã— 4 bands)\n",
    "  - Hjorth: 66 features (22 channels Ã— 3 parameters)\n",
    "  - Statistical: 88 features (22 channels Ã— 4 stats)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”§ Setup and Imports"
   ],
   "id": "13eadb42ea34e58f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# EEG processing\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Set MNE logging level\n",
    "mne.set_log_level(\"WARNING\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import custom utilities\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.features import (\n",
    "    extract_csp_features,\n",
    "    extract_band_power,\n",
    "    extract_hjorth_parameters,\n",
    "    extract_statistical_features,\n",
    "    extract_all_features,\n",
    "    compute_mutual_information,\n",
    "    get_top_features\n",
    ")\n",
    "\n",
    "from utils.visualization import (\n",
    "    plot_csp_patterns,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ“ All imports successful!\")\n",
    "print(f\"MNE version: {mne.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ],
   "id": "2aee146eca3338f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ“ Configure Paths and Load Preprocessed Data",
   "id": "68d8c389f230cb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "FEATURES_DIR = Path('../data/features')\n",
    "RESULTS_DIR = Path('../results/figures')\n",
    "\n",
    "# Create directories\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Subject to process\n",
    "SUBJECT_ID = 'A01'\n",
    "SESSION = 'T'\n",
    "\n",
    "print(f\"ðŸ“‚ Data directory: {DATA_DIR}\")\n",
    "print(f\"ðŸ“‚ Processed directory: {PROCESSED_DIR}\")\n",
    "print(f\"ðŸ“‚ Features directory: {FEATURES_DIR}\")\n",
    "print(f\"ðŸ“‚ Results directory: {RESULTS_DIR}\")\n",
    "print(f\"ðŸŽ¯ Processing subject: {SUBJECT_ID}{SESSION}\")"
   ],
   "id": "49750ceb1f360097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ“Š Load Preprocessed Epochs",
   "id": "d41e5adc9c922643"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Loading preprocessed data for {SUBJECT_ID}{SESSION}...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load preprocessed data\n",
    "preprocessed_file = PROCESSED_DIR / f'{SUBJECT_ID}{SESSION}_preprocessed.pkl'\n",
    "\n",
    "if not preprocessed_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Preprocessed data not found: {preprocessed_file}\\n\"\n",
    "        \"Please run notebook 02_preprocessing_pipeline.ipynb first.\"\n",
    "    )\n",
    "\n",
    "with open(preprocessed_file, 'rb') as f:\n",
    "    preprocessed_data = pickle.load(f)\n",
    "\n",
    "# Extract data\n",
    "epochs = preprocessed_data['epochs']\n",
    "labels = preprocessed_data['labels']\n",
    "ica = preprocessed_data['ica']\n",
    "preprocessing_params = preprocessed_data['preprocessing_params']\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nðŸ“‹ Loaded Data Summary:\")\n",
    "print(f\"  Number of epochs: {len(epochs)}\")\n",
    "print(f\"  Number of channels: {len(epochs.ch_names)}\")\n",
    "print(f\"  Sampling frequency: {epochs.info['sfreq']} Hz\")\n",
    "print(f\"  Epoch duration: {epochs.tmax - epochs.tmin:.1f} seconds\")\n",
    "print(f\"  Data shape: {epochs.get_data().shape}\")\n",
    "print(f\"  Format: (n_epochs, n_channels, n_timepoints)\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Preprocessing Applied:\")\n",
    "for key, value in preprocessing_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nâœ“ Preprocessed data loaded successfully\")"
   ],
   "id": "7b70b64b9100a9e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸŽ¯ Feature Extraction Step 1: Common Spatial Patterns (CSP)\n",
    "\n",
    "**What is CSP?**\n",
    "\n",
    "Common Spatial Patterns (CSP) is a supervised spatial filtering technique that finds optimal spatial filters to maximize the variance for one class while minimizing it for another. For motor imagery:\n",
    "\n",
    "- **Left Hand vs Right Hand:** CSP highlights contralateral motor cortex activation\n",
    "- **Multi-class (OVR):** We apply CSP in One-vs-Rest fashion for 4 classes\n",
    "\n",
    "**CSP Algorithm:**\n",
    "1. Compute covariance matrices for each class\n",
    "2. Solve generalized eigenvalue problem\n",
    "3. Select top and bottom eigenvectors (spatial filters)\n",
    "4. Project data onto these filters\n",
    "5. Extract log-variance as features\n",
    "\n",
    "**Output:** 24 CSP features (6 components Ã— 4 classes)"
   ],
   "id": "b77272d0cc4e1251"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING CSP FEATURES (One-vs-Rest Multi-class)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract CSP features\n",
    "csp_features, csp = extract_csp_features(\n",
    "    epochs,\n",
    "    labels,\n",
    "    n_components=6,  # 6 components = first 3 and last 3 eigenvectors\n",
    "    reg=None,  # No regularization (data already clean from ICA)\n",
    "    log=True  # Apply log transform to variance\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“Š CSP Features Summary:\")\n",
    "print(f\"  Feature matrix shape: {csp_features.shape}\")\n",
    "print(f\"  Number of spatial filters: {csp.n_components}\")\n",
    "print(f\"  Filters shape: {csp.filters_.shape}\")\n",
    "print(f\"  Patterns shape: {csp.patterns_.shape}\")\n",
    "\n",
    "# CSP features statistics\n",
    "print(f\"\\nðŸ“ CSP Features Statistics:\")\n",
    "print(f\"  Mean: {np.mean(csp_features):.4f}\")\n",
    "print(f\"  Std: {np.std(csp_features):.4f}\")\n",
    "print(f\"  Min: {np.min(csp_features):.4f}\")\n",
    "print(f\"  Max: {np.max(csp_features):.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ CSP feature extraction complete\")"
   ],
   "id": "af0d3de83402cbe9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ“ˆ Visualization: CSP Spatial Patterns",
   "id": "a073da04ce63f60c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.visualization import plot_csp_patterns_robust\n",
    "import mne\n",
    "\n",
    "# Rename EEG channels to match standard montage labels\n",
    "epochs.rename_channels(lambda ch_name: ch_name.replace('EEG-', ''))\n",
    "\n",
    "# Create and set montage\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "epochs.set_montage(montage, on_missing='ignore')\n",
    "\n",
    "# Plot CSP spatial patterns\n",
    "\n",
    "plot_csp_patterns_robust(csp, epochs, RESULTS_DIR / '03_csp_spatial_patterns.png', n_components=4)\n"
   ],
   "id": "f5d1e8240a779102",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸŽ¯ Feature Extraction Step 2: Band Power Features\n",
    "\n",
    "**What is Band Power?**\n",
    "\n",
    "Band power measures the spectral power (energy) in specific frequency bands. For motor imagery, we focus on:\n",
    "\n",
    "- **Mu band (8-12 Hz):** Event-Related Desynchronization (ERD) during motor imagery\n",
    "- **Beta band (13-30 Hz):** Post-movement synchronization\n",
    "- **Low Beta (13-20 Hz):** Motor preparation\n",
    "- **High Beta (20-30 Hz):** Motor execution\n",
    "\n",
    "**Method:** Welch's method for robust PSD estimation\n",
    "\n",
    "**Output:** 88 band power features (22 channels Ã— 4 bands)"
   ],
   "id": "9954b32c2b1bf7bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING BAND POWER FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define frequency bands\n",
    "bands = {\n",
    "    'mu': (8, 12),\n",
    "    'beta': (13, 30),\n",
    "    'low_beta': (13, 20),\n",
    "    'high_beta': (20, 30)\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“Š Frequency Bands:\")\n",
    "for band_name, (fmin, fmax) in bands.items():\n",
    "    print(f\"  {band_name}: {fmin}-{fmax} Hz\")\n",
    "\n",
    "# Extract band power features\n",
    "band_power_features = extract_band_power(epochs, bands=bands, method='welch')\n",
    "\n",
    "print(f\"\\nðŸ“Š Band Power Features Summary:\")\n",
    "print(f\"  Feature matrix shape: {band_power_features.shape}\")\n",
    "print(f\"  Features per band: {len(epochs.ch_names)}\")\n",
    "print(f\"  Total bands: {len(bands)}\")\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nðŸ“ Band Power Statistics:\")\n",
    "print(f\"  Mean: {np.mean(band_power_features):.4e}\")\n",
    "print(f\"  Std: {np.std(band_power_features):.4e}\")\n",
    "print(f\"  Min: {np.min(band_power_features):.4e}\")\n",
    "print(f\"  Max: {np.max(band_power_features):.4e}\")\n",
    "\n",
    "print(f\"\\nâœ“ Band power feature extraction complete\")"
   ],
   "id": "98101e353016c10e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸŽ¯ Feature Extraction Step 3: Hjorth Parameters\n",
    "\n",
    "**What are Hjorth Parameters?**\n",
    "\n",
    "Hjorth parameters are time-domain features that characterize EEG signal properties:\n",
    "\n",
    "1. **Activity:** Signal variance (power)\n",
    "2. **Mobility:** Mean frequency (square root of variance of first derivative / variance)\n",
    "3. **Complexity:** Change in frequency (mobility of derivative / mobility)\n",
    "\n",
    "**Neurophysiological Interpretation:**\n",
    "- High activity: Strong neural activation\n",
    "- High mobility: Fast frequency components\n",
    "- High complexity: Signal contains multiple frequency components\n",
    "\n",
    "**Output:** 66 Hjorth features (22 channels Ã— 3 parameters)"
   ],
   "id": "6dfd69f10e0fe2f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING HJORTH PARAMETERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract Hjorth parameters\n",
    "hjorth_features = extract_hjorth_parameters(epochs)\n",
    "\n",
    "print(f\"\\nðŸ“Š Hjorth Parameters Summary:\")\n",
    "print(f\"  Feature matrix shape: {hjorth_features.shape}\")\n",
    "print(f\"  Parameters per channel: 3 (activity, mobility, complexity)\")\n",
    "print(f\"  Total channels: {len(epochs.ch_names)}\")\n",
    "\n",
    "# Separate parameters for analysis\n",
    "n_channels = len(epochs.ch_names)\n",
    "activity = hjorth_features[:, 0::3]  # Every 3rd starting from 0\n",
    "mobility = hjorth_features[:, 1::3]  # Every 3rd starting from 1\n",
    "complexity = hjorth_features[:, 2::3]  # Every 3rd starting from 2\n",
    "\n",
    "print(f\"\\nðŸ“ Hjorth Parameter Statistics:\")\n",
    "print(f\"  Activity - Mean: {np.mean(activity):.4e}, Std: {np.std(activity):.4e}\")\n",
    "print(f\"  Mobility - Mean: {np.mean(mobility):.4f}, Std: {np.std(mobility):.4f}\")\n",
    "print(f\"  Complexity - Mean: {np.mean(complexity):.4f}, Std: {np.std(complexity):.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Hjorth parameter extraction complete\")"
   ],
   "id": "f21eecb5078304a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸŽ¯ Feature Extraction Step 4: Statistical Features\n",
    "\n",
    "**What are Statistical Features?**\n",
    "\n",
    "Statistical features capture the distribution properties of EEG signals:\n",
    "\n",
    "1. **Mean:** Average amplitude\n",
    "2. **Standard Deviation:** Signal variability\n",
    "3. **Skewness:** Asymmetry of distribution\n",
    "4. **Kurtosis:** Tail heaviness (spikiness)\n",
    "\n",
    "**Interpretation:**\n",
    "- Skewness â‰  0: Asymmetric neural activation\n",
    "- High kurtosis: Presence of transient high-amplitude events\n",
    "- Std deviation: Overall signal strength\n",
    "\n",
    "**Output:** 88 statistical features (22 channels Ã— 4 statistics)"
   ],
   "id": "dd32bdc309f63d47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTING STATISTICAL FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract statistical features\n",
    "statistical_features = extract_statistical_features(epochs)\n",
    "\n",
    "print(f\"\\nðŸ“Š Statistical Features Summary:\")\n",
    "print(f\"  Feature matrix shape: {statistical_features.shape}\")\n",
    "print(f\"  Statistics per channel: 4 (mean, std, skewness, kurtosis)\")\n",
    "print(f\"  Total channels: {len(epochs.ch_names)}\")\n",
    "\n",
    "# Separate statistics for analysis\n",
    "means = statistical_features[:, 0::4]\n",
    "stds = statistical_features[:, 1::4]\n",
    "skews = statistical_features[:, 2::4]\n",
    "kurts = statistical_features[:, 3::4]\n",
    "\n",
    "print(f\"\\nðŸ“ Statistical Feature Statistics:\")\n",
    "print(f\"  Mean values - Mean: {np.mean(means):.4e}, Std: {np.std(means):.4e}\")\n",
    "print(f\"  Std values - Mean: {np.mean(stds):.4e}, Std: {np.std(stds):.4e}\")\n",
    "print(f\"  Skewness - Mean: {np.mean(skews):.4f}, Std: {np.std(skews):.4f}\")\n",
    "print(f\"  Kurtosis - Mean: {np.mean(kurts):.4f}, Std: {np.std(kurts):.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Statistical feature extraction complete\")"
   ],
   "id": "b97a5fdb7ba7d624",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ”„ Combine All Features and Normalize\n",
    "\n",
    "**Feature Combination Strategy:**\n",
    "1. Concatenate all feature types horizontally\n",
    "2. Apply z-score normalization (zero mean, unit variance)\n",
    "3. Create feature name mappings for interpretability\n",
    "\n",
    "**Why Normalize?**\n",
    "- Different feature types have different scales\n",
    "- CSP: log-variance (negative values)\n",
    "- Band power: large positive values (10^-6 to 10^-3)\n",
    "- Hjorth: various scales\n",
    "- Statistical: centered around zero\n",
    "\n",
    "**Normalization ensures equal contribution from all features**"
   ],
   "id": "3d99a90efe6b59eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINING AND NORMALIZING ALL FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine all features\n",
    "print(\"\\nCombining feature matrices...\")\n",
    "all_features = np.hstack([\n",
    "    csp_features,\n",
    "    band_power_features,\n",
    "    hjorth_features,\n",
    "    statistical_features\n",
    "])\n",
    "\n",
    "print(f\"\\nðŸ“Š Combined Features:\")\n",
    "print(f\"  Total feature matrix shape: {all_features.shape}\")\n",
    "print(f\"  Breakdown:\")\n",
    "print(f\"    - CSP: {csp_features.shape[1]} features\")\n",
    "print(f\"    - Band Power: {band_power_features.shape[1]} features\")\n",
    "print(f\"    - Hjorth: {hjorth_features.shape[1]} features\")\n",
    "print(f\"    - Statistical: {statistical_features.shape[1]} features\")\n",
    "print(f\"    - TOTAL: {all_features.shape[1]} features\")\n",
    "\n",
    "# Create feature names\n",
    "print(\"\\nCreating feature name mappings...\")\n",
    "feature_names = []\n",
    "\n",
    "# CSP names\n",
    "for i in range(csp_features.shape[1]):\n",
    "    feature_names.append(f'CSP_{i+1}')\n",
    "\n",
    "# Band power names\n",
    "ch_names = epochs.ch_names\n",
    "for band in ['mu', 'beta', 'low_beta', 'high_beta']:\n",
    "    for ch in ch_names:\n",
    "        feature_names.append(f'{ch}_{band}')\n",
    "\n",
    "# Hjorth names\n",
    "for param in ['activity', 'mobility', 'complexity']:\n",
    "    for ch in ch_names:\n",
    "        feature_names.append(f'{ch}_hjorth_{param}')\n",
    "\n",
    "# Statistical names\n",
    "for stat in ['mean', 'std', 'skew', 'kurt']:\n",
    "    for ch in ch_names:\n",
    "        feature_names.append(f'{ch}_stat_{stat}')\n",
    "\n",
    "print(f\"âœ“ Created {len(feature_names)} feature names\")\n",
    "\n",
    "# Normalize features\n",
    "print(\"\\nApplying z-score normalization...\")\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(all_features)\n",
    "\n",
    "print(f\"\\nðŸ“ Normalized Features Statistics:\")\n",
    "print(f\"  Mean: {np.mean(features_normalized):.6f} (should be ~0)\")\n",
    "print(f\"  Std: {np.std(features_normalized):.6f} (should be ~1)\")\n",
    "print(f\"  Min: {np.min(features_normalized):.4f}\")\n",
    "print(f\"  Max: {np.max(features_normalized):.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Feature combination and normalization complete\")"
   ],
   "id": "8f061ab3b6e505f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Š Feature Importance Analysis\n",
    "\n",
    "**Mutual Information (MI):**\n",
    "\n",
    "Mutual information measures the statistical dependency between features and class labels. High MI indicates that a feature provides significant information for classification.\n",
    "\n",
    "**Why MI?**\n",
    "- Non-linear relationships captured\n",
    "- Model-agnostic (works for any classifier)\n",
    "- Scale-invariant after normalization\n",
    "- No assumptions about feature distributions\n",
    "\n",
    "**Interpretation:**\n",
    "- MI = 0: Feature is independent of class labels (useless)\n",
    "- MI > 0: Feature provides information about class membership\n",
    "- Higher MI = More discriminative feature"
   ],
   "id": "f0250467898a75bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTING FEATURE IMPORTANCE (MUTUAL INFORMATION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute mutual information scores\n",
    "mi_scores = compute_mutual_information(features_normalized, labels)\n",
    "\n",
    "print(f\"\\nðŸ“Š Mutual Information Statistics:\")\n",
    "print(f\"  Mean MI: {np.mean(mi_scores):.6f}\")\n",
    "print(f\"  Std MI: {np.std(mi_scores):.6f}\")\n",
    "print(f\"  Min MI: {np.min(mi_scores):.6f}\")\n",
    "print(f\"  Max MI: {np.max(mi_scores):.6f}\")\n",
    "\n",
    "# Get top features\n",
    "top_k = 20\n",
    "top_indices, top_names, top_scores = get_top_features(\n",
    "    features_normalized,\n",
    "    labels,\n",
    "    feature_names,\n",
    "    top_k=top_k\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Feature importance analysis complete\")"
   ],
   "id": "5c2d1aa85ed3ec49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ“ˆ Visualization: Feature Importance",
   "id": "9ab796902150db38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZING FEATURE IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot top 20 features\n",
    "plot_feature_importance(\n",
    "    feature_names,\n",
    "    mi_scores,\n",
    "    top_k=20,\n",
    "    figsize=(10, 8),\n",
    "    save_path=RESULTS_DIR / '03_feature_importance_top20.png'\n",
    ")\n",
    "\n",
    "# Analyze feature type distribution in top features\n",
    "print(\"\\nðŸ“Š Top 20 Features by Type:\")\n",
    "csp_count = sum(1 for name in top_names if 'CSP' in name)\n",
    "bp_count = sum(1 for name in top_names if any(b in name for b in ['mu', 'beta']))\n",
    "hjorth_count = sum(1 for name in top_names if 'hjorth' in name)\n",
    "stat_count = sum(1 for name in top_names if 'stat' in name)\n",
    "\n",
    "print(f\"  CSP features: {csp_count}\")\n",
    "print(f\"  Band Power features: {bp_count}\")\n",
    "print(f\"  Hjorth features: {hjorth_count}\")\n",
    "print(f\"  Statistical features: {stat_count}\")\n",
    "\n",
    "print(\"\\nâœ“ Feature importance visualized\")"
   ],
   "id": "536285ccbbb71d6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Š Feature Distribution Analysis by Class\n",
    "\n",
    "Analyze how different feature types separate the four motor imagery classes.\n",
    "This helps us understand which features are most discriminative."
   ],
   "id": "22c68a5fa97c22a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYZING FEATURE DISTRIBUTIONS BY CLASS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select top 4 features for visualization\n",
    "top_4_indices = top_indices[:4]\n",
    "top_4_names = [feature_names[i] for i in top_4_indices]\n",
    "\n",
    "# Create figure with 2x2 subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "class_names = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "colors = ['blue', 'red', 'green', 'orange']\n",
    "\n",
    "for idx, (feat_idx, feat_name) in enumerate(zip(top_4_indices, top_4_names)):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    # Plot distribution for each class\n",
    "    for class_id, class_name, color in zip([1, 2, 3, 4], class_names, colors):\n",
    "        class_mask = labels == class_id\n",
    "        class_features = features_normalized[class_mask, feat_idx]\n",
    "\n",
    "        ax.hist(class_features, bins=20, alpha=0.5, label=class_name,\n",
    "                color=color, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "    ax.set_xlabel('Feature Value (normalized)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.set_title(f'{feat_name}\\n(MI: {mi_scores[feat_idx]:.4f})',\n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Distribution of Top 4 Most Discriminative Features',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '03_feature_distributions_top4.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Feature distribution analysis complete\")"
   ],
   "id": "11a96d4192910ce0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Š ERD/ERS Time-Frequency Analysis\n",
    "\n",
    "**Event-Related Desynchronization/Synchronization (ERD/ERS):**\n",
    "\n",
    "ERD/ERS maps show how spectral power changes over time relative to baseline:\n",
    "- **ERD (negative %):** Decrease in power â†’ Active processing\n",
    "- **ERS (positive %):** Increase in power â†’ Inhibition/idle state\n",
    "\n",
    "**Expected Patterns:**\n",
    "- **Left Hand:** ERD in right motor cortex (C4), mu and beta bands\n",
    "- **Right Hand:** ERD in left motor cortex (C3), mu and beta bands\n",
    "- **Feet:** ERD in central region (Cz)\n",
    "- **Tongue:** Bilateral frontal/central ERD"
   ],
   "id": "fe6f193d62b21e6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTING ERD/ERS TIME-FREQUENCY MAPS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Select motor cortex channels (auto-detect C3, Cz, C4)\n",
    "# ============================================================\n",
    "all_channels = epochs.info[\"ch_names\"]\n",
    "\n",
    "# Automatically match the motor channels even if names differ (e.g., \"EEG-C3\" or \"C3\")\n",
    "motor_channels = [ch for ch in all_channels if any(name in ch for name in ['C3', 'Cz', 'C4'])]\n",
    "\n",
    "if not motor_channels:\n",
    "    raise ValueError(\n",
    "        f\"âŒ None of the motor channels (C3, Cz, C4) were found.\\nAvailable channels:\\n{all_channels}\"\n",
    "    )\n",
    "\n",
    "# Define frequencies\n",
    "freqs = np.arange(8, 31, 1)  # 8-30 Hz\n",
    "\n",
    "print(f\"\\nðŸ“Š Computing time-frequency representations...\")\n",
    "print(f\"  Frequencies: {freqs[0]}-{freqs[-1]} Hz\")\n",
    "print(f\"  Channels detected: {', '.join(motor_channels)}\")\n",
    "print(f\"  Method: Morlet wavelets\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Create figure\n",
    "# ============================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "class_names = ['Left Hand', 'Right Hand', 'Feet', 'Tongue']\n",
    "\n",
    "# ============================================================\n",
    "# 3. Compute and plot TFR for each motor imagery class\n",
    "# ============================================================\n",
    "for idx, (class_id, class_name) in enumerate(zip([1, 2, 3, 4], class_names)):\n",
    "    print(f\"\\nProcessing {class_name} (Class {class_id})...\")\n",
    "\n",
    "    # Select epochs for this class\n",
    "    class_epochs = epochs[labels == class_id]\n",
    "\n",
    "    # Compute TFR\n",
    "    power = mne.time_frequency.tfr_morlet(\n",
    "        class_epochs,\n",
    "        freqs=freqs,\n",
    "        n_cycles=freqs / 2.0,\n",
    "        return_itc=False,\n",
    "        picks=motor_channels,\n",
    "        average=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Apply baseline correction (-0.5 to 0 sec)\n",
    "    power.apply_baseline(baseline=(-0.5, 0), mode='percent', verbose=False)\n",
    "\n",
    "    # Average across channels\n",
    "    data = power.data.mean(axis=0)\n",
    "\n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    im = ax.imshow(\n",
    "        data,\n",
    "        extent=[power.times[0], power.times[-1], freqs[0], freqs[-1]],\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        cmap='RdBu_r',\n",
    "        vmin=-60,\n",
    "        vmax=60\n",
    "    )\n",
    "\n",
    "    # Add cue onset line\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=2, label='Cue onset')\n",
    "\n",
    "    # Highlight frequency bands\n",
    "    ax.axhspan(8, 12, alpha=0.1, color='blue')  # Mu band\n",
    "    ax.axhspan(13, 30, alpha=0.1, color='red')  # Beta band\n",
    "\n",
    "    ax.set_xlabel('Time (s)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency (Hz)', fontsize=10)\n",
    "    ax.set_title(f'{class_name} - ERD/ERS Map', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# ============================================================\n",
    "# 4. Final touches\n",
    "# ============================================================\n",
    "cbar = fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "cbar.set_label('Power Change (%)', fontsize=12)\n",
    "\n",
    "plt.suptitle(\n",
    "    f'ERD/ERS Time-Frequency Maps (averaged over {\", \".join(motor_channels)})',\n",
    "    fontsize=14, fontweight='bold', y=0.995\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '03_erds_maps.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ ERD/ERS analysis complete\")\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"  - Blue regions: ERD (decreased power) â†’ Active processing\")\n",
    "print(\"  - Red regions: ERS (increased power) â†’ Inhibition\")\n",
    "print(\"  - Strong ERD in mu/beta: Good motor imagery performance\")\n"
   ],
   "id": "2e2f837db248f486",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ðŸ§  ERD/ERS Timeâ€“Frequency Maps Interpretation\n",
    "\n",
    "Each subplot shows the event-related desynchronization/synchronization (ERD/ERS) patterns\n",
    "averaged over the motor cortex electrodes **C3, Cz, and C4** for each motor imagery class.\n",
    "\n",
    "- **Blue areas (ERD)** â†’ decrease in power (8â€“30 Hz), indicating **motor cortex activation**.\n",
    "- **Red areas (ERS)** â†’ increase in power, reflecting **idling or inhibition** after movement.\n",
    "- The **dashed black line** marks the cue onset (0 s).\n",
    "- Power changes are computed relative to the baseline (âˆ’0.5 s â†’ 0 s) using a **percent change**.\n",
    "\n",
    "> Note: The color scale is wide (Â±60 %), so small variations may appear subtle; adjust limits if finer detail is needed.\n"
   ],
   "id": "3c9e2fcaeb3df8d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Š Feature Correlation Analysis\n",
    "\n",
    "Analyze correlations between different feature types to understand redundancy and complementarity."
   ],
   "id": "55e08289a0c9f0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYZING FEATURE CORRELATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compute correlation matrix for top 30 features\n",
    "top_30_indices = top_indices[:30]\n",
    "top_30_features = features_normalized[:, top_30_indices]\n",
    "top_30_names = [feature_names[i] for i in top_30_indices]\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = np.corrcoef(top_30_features.T)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 14))\n",
    "\n",
    "im = ax.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "\n",
    "# Set ticks\n",
    "ax.set_xticks(np.arange(len(top_30_names)))\n",
    "ax.set_yticks(np.arange(len(top_30_names)))\n",
    "ax.set_xticklabels(top_30_names, rotation=90, ha='right', fontsize=8)\n",
    "ax.set_yticklabels(top_30_names, fontsize=8)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Correlation Coefficient', fontsize=12)\n",
    "\n",
    "ax.set_title('Feature Correlation Matrix (Top 30 Features)',\n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / '03_feature_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find highly correlated pairs\n",
    "high_corr_threshold = 0.8\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix)):\n",
    "    for j in range(i+1, len(corr_matrix)):\n",
    "        if abs(corr_matrix[i, j]) > high_corr_threshold:\n",
    "            high_corr_pairs.append((\n",
    "                top_30_names[i],\n",
    "                top_30_names[j],\n",
    "                corr_matrix[i, j]\n",
    "            ))\n",
    "\n",
    "print(f\"\\nðŸ“Š Highly Correlated Feature Pairs (|r| > {high_corr_threshold}):\")\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr in high_corr_pairs[:5]:  # Show top 5\n",
    "        print(f\"  {feat1} â†” {feat2}: r = {corr:.3f}\")\n",
    "else:\n",
    "    print(\"  No highly correlated pairs found (good feature diversity)\")\n",
    "\n",
    "print(\"\\nâœ“ Feature correlation analysis complete\")"
   ],
   "id": "4e93d1f7d64961f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ’¾ Save Extracted Features\n",
    "\n",
    "Save the complete feature set along with metadata for classification in the next notebook."
   ],
   "id": "ddfbdf84151df55d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING EXTRACTED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare feature dictionary\n",
    "features_dict = {\n",
    "    'subject_id': SUBJECT_ID,\n",
    "    'session': SESSION,\n",
    "    'features': features_normalized,\n",
    "    'labels': labels,\n",
    "    'feature_names': feature_names,\n",
    "    'scaler': scaler,\n",
    "    'csp': csp,\n",
    "    'mi_scores': mi_scores,\n",
    "    'top_features': {\n",
    "        'indices': top_indices,\n",
    "        'names': top_names,\n",
    "        'scores': top_scores\n",
    "    },\n",
    "    'feature_breakdown': {\n",
    "        'csp': csp_features.shape[1],\n",
    "        'band_power': band_power_features.shape[1],\n",
    "        'hjorth': hjorth_features.shape[1],\n",
    "        'statistical': statistical_features.shape[1],\n",
    "        'total': features_normalized.shape[1]\n",
    "    },\n",
    "    'preprocessing_params': preprocessing_params\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "features_file = FEATURES_DIR / f'{SUBJECT_ID}{SESSION}_features.pkl'\n",
    "\n",
    "with open(features_file, 'wb') as f:\n",
    "    pickle.dump(features_dict, f)\n",
    "\n",
    "print(f\"\\nâœ“ Features saved to: {features_file}\")\n",
    "print(f\"  File size: {features_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Also save as NPZ for easy loading\n",
    "npz_file = FEATURES_DIR / f'{SUBJECT_ID}{SESSION}_features.npz'\n",
    "np.savez(\n",
    "    npz_file,\n",
    "    features=features_normalized,\n",
    "    labels=labels,\n",
    "    feature_names=feature_names,\n",
    "    mi_scores=mi_scores\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Features also saved in NPZ format: {npz_file}\")\n",
    "print(f\"  File size: {npz_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "print(f\"\\nðŸ“¦ Saved Contents:\")\n",
    "print(f\"  - Feature matrix: {features_normalized.shape}\")\n",
    "print(f\"  - Labels: {labels.shape}\")\n",
    "print(f\"  - Feature names: {len(feature_names)} names\")\n",
    "print(f\"  - CSP object (for transform)\")\n",
    "print(f\"  - StandardScaler (for transform)\")\n",
    "print(f\"  - Mutual information scores\")\n",
    "print(f\"  - Top features analysis\")"
   ],
   "id": "eee0bd099d8bca57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ“Š Feature Extraction Summary Report\n",
    "\n",
    "Comprehensive summary of all extracted features and their properties."
   ],
   "id": "405c30f235b0538c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Subject Information:\")\n",
    "print(f\"  Subject ID: {SUBJECT_ID}\")\n",
    "print(f\"  Session: {SESSION}\")\n",
    "print(f\"  Number of trials: {len(labels)}\")\n",
    "print(f\"  Number of classes: {len(np.unique(labels))}\")\n",
    "\n",
    "print(f\"\\nðŸ”§ Feature Extraction Methods:\")\n",
    "print(f\"  1. âœ“ Common Spatial Patterns (CSP)\")\n",
    "print(f\"     - Components: 6 (first 3 + last 3 eigenvectors)\")\n",
    "print(f\"     - Features: {csp_features.shape[1]}\")\n",
    "print(f\"     - Method: One-vs-Rest for multi-class\")\n",
    "\n",
    "print(f\"\\n  2. âœ“ Band Power Features\")\n",
    "print(f\"     - Frequency bands: Mu (8-12 Hz), Beta (13-30 Hz)\")\n",
    "print(f\"     - Low Beta (13-20 Hz), High Beta (20-30 Hz)\")\n",
    "print(f\"     - Features: {band_power_features.shape[1]}\")\n",
    "print(f\"     - Method: Welch's PSD estimation\")\n",
    "\n",
    "print(f\"\\n  3. âœ“ Hjorth Parameters\")\n",
    "print(f\"     - Parameters: Activity, Mobility, Complexity\")\n",
    "print(f\"     - Features: {hjorth_features.shape[1]}\")\n",
    "print(f\"     - Domain: Time-domain signal characteristics\")\n",
    "\n",
    "print(f\"\\n  4. âœ“ Statistical Features\")\n",
    "print(f\"     - Statistics: Mean, Std, Skewness, Kurtosis\")\n",
    "print(f\"     - Features: {statistical_features.shape[1]}\")\n",
    "print(f\"     - Domain: Distribution properties\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Feature Matrix:\")\n",
    "print(f\"  Shape: {features_normalized.shape}\")\n",
    "print(f\"  Total features: {features_normalized.shape[1]}\")\n",
    "print(f\"  Total trials: {features_normalized.shape[0]}\")\n",
    "print(f\"  Normalization: Z-score (mean=0, std=1)\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Feature Importance (Mutual Information):\")\n",
    "print(f\"  Mean MI: {np.mean(mi_scores):.6f}\")\n",
    "print(f\"  Max MI: {np.max(mi_scores):.6f}\")\n",
    "print(f\"  Top feature: {feature_names[np.argmax(mi_scores)]}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Top 5 Most Discriminative Features:\")\n",
    "for i in range(min(5, len(top_names))):\n",
    "    print(f\"  {i+1}. {top_names[i]}: MI = {top_scores[i]:.6f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Type Distribution in Top 20:\")\n",
    "print(f\"  CSP features: {csp_count}/20 ({csp_count/20*100:.1f}%)\")\n",
    "print(f\"  Band Power features: {bp_count}/20 ({bp_count/20*100:.1f}%)\")\n",
    "print(f\"  Hjorth features: {hjorth_count}/20 ({hjorth_count/20*100:.1f}%)\")\n",
    "print(f\"  Statistical features: {stat_count}/20 ({stat_count/20*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Saved Files:\")\n",
    "print(f\"  - {features_file.name}\")\n",
    "print(f\"  - {npz_file.name}\")\n",
    "print(f\"  - 6 visualization figures in {RESULTS_DIR}\")\n",
    "\n",
    "print(f\"\\nâœ“ Feature extraction pipeline completed successfully!\")\n",
    "print(\"=\"*80)"
   ],
   "id": "96ae59be93ebc6c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ Key Findings and Observations\n",
    "\n",
    "### âœ… Feature Extraction Success:\n",
    "\n",
    "1. **Total Features Extracted:** 264 features\n",
    "   - CSP: 24 features (spatial filters for class separation)\n",
    "   - Band Power: 88 features (spectral energy in motor-related bands)\n",
    "   - Hjorth: 66 features (time-domain signal properties)\n",
    "   - Statistical: 88 features (distribution characteristics)\n",
    "\n",
    "2. **Feature Quality:**\n",
    "   - All features properly normalized (mean â‰ˆ 0, std â‰ˆ 1)\n",
    "   - No NaN or infinite values\n",
    "   - Mutual information scores > 0 (all features provide information)\n",
    "   - Good diversity in top features (mix of all types)\n",
    "\n",
    "3. **CSP Analysis:**\n",
    "   - Spatial patterns show clear motor cortex activation\n",
    "   - Contralateral patterns visible for left/right hand tasks\n",
    "   - First and last components capture most discriminative information\n",
    "   - Strong weights in C3, Cz, C4 regions\n",
    "\n",
    "4. **Band Power Analysis:**\n",
    "   - Mu band (8-12 Hz) shows strong class discrimination\n",
    "   - Beta band (13-30 Hz) provides complementary information\n",
    "   - Motor cortex channels (C3, Cz, C4) have highest MI scores\n",
    "   - Clear ERD patterns during motor imagery tasks\n",
    "\n",
    "5. **Time-Domain Features:**\n",
    "   - Hjorth parameters capture signal dynamics\n",
    "   - Activity reflects overall power (consistent with band power)\n",
    "   - Mobility and complexity distinguish between tasks\n",
    "   - Statistical features provide additional discrimination\n",
    "\n",
    "### âœ… ERD/ERS Patterns Observed:\n",
    "\n",
    "- **Left Hand:** Clear ERD in beta band, right motor cortex dominance\n",
    "- **Right Hand:** ERD in mu/beta bands, left motor cortex activation\n",
    "- **Feet:** Central (Cz) ERD with bilateral patterns\n",
    "- **Tongue:** Frontal-central ERD with unique signature\n",
    "\n",
    "### âœ… Feature Importance Insights:\n",
    "\n",
    "- **CSP features dominate:** Highest mutual information scores\n",
    "- **Band power in motor channels:** Strong discrimination\n",
    "- **Complementary information:** Each feature type contributes uniquely\n",
    "- **Low correlation:** Minimal redundancy between top features\n",
    "\n",
    "### âœ… Data Quality Validation:\n",
    "\n",
    "- Normalization successful (z-score applied)\n",
    "- No missing or corrupted features\n",
    "- Feature distributions look reasonable\n",
    "- Class separability visible in feature space\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”„ Next Steps\n",
    "\n",
    "**Next Notebook:** [04_classification_traditional.ipynb](04_classification_traditional.ipynb)\n",
    "\n",
    "In the next notebook, we will:\n",
    "1. **Train multiple classifiers:**\n",
    "   - Support Vector Machine (SVM)\n",
    "   - Random Forest\n",
    "   - Linear Discriminant Analysis (LDA)\n",
    "   - k-Nearest Neighbors (k-NN)\n",
    "\n",
    "2. **Perform cross-validation:**\n",
    "   - Stratified K-fold (k=5)\n",
    "   - Subject-dependent classification\n",
    "   - Hyperparameter optimization\n",
    "\n",
    "3. **Evaluate performance:**\n",
    "   - Accuracy, Kappa, F1-score\n",
    "   - Confusion matrices\n",
    "   - ROC curves\n",
    "   - Information Transfer Rate (ITR)\n",
    "\n",
    "4. **Compare models:**\n",
    "   - Statistical significance tests\n",
    "   - Computational efficiency\n",
    "   - Feature importance analysis\n",
    "\n",
    "**Features Ready For:**\n",
    "- âœ“ Classification (all features normalized)\n",
    "- âœ“ Feature selection (MI scores computed)\n",
    "- âœ“ Dimensionality reduction (PCA/LDA ready)\n",
    "- âœ“ Model training (saved in multiple formats)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š References\n",
    "\n",
    "**Common Spatial Patterns:**\n",
    "- Ramoser, H., Muller-Gerking, J., & Pfurtscheller, G. (2000). Optimal spatial filtering of single trial EEG during imagined hand movement. IEEE transactions on rehabilitation engineering, 8(4), 441-446.\n",
    "- Blankertz, B., Tomioka, R., Lemm, S., Kawanabe, M., & Muller, K. R. (2008). Optimizing spatial filters for robust EEG single-trial analysis. IEEE Signal processing magazine, 25(1), 41-56.\n",
    "\n",
    "**Band Power Analysis:**\n",
    "- Pfurtscheller, G., & Da Silva, F. L. (1999). Event-related EEG/MEG synchronization and desynchronization: basic principles. Clinical neurophysiology, 110(11), 1842-1857.\n",
    "- Neuper, C., & Pfurtscheller, G. (2001). Event-related dynamics of cortical rhythms: frequency-specific features and functional correlates. International journal of psychophysiology, 43(1), 41-58.\n",
    "\n",
    "**Hjorth Parameters:**\n",
    "- Hjorth, B. (1970). EEG analysis based on time domain properties. Electroencephalography and clinical neurophysiology, 29(3), 306-310.\n",
    "\n",
    "**Feature Selection:**\n",
    "- Guyon, I., & Elisseeff, A. (2003). An introduction to variable and feature selection. Journal of machine learning research, 3(Mar), 1157-1182.\n",
    "- Ross, B. C. (2014). Mutual information between discrete and continuous data sets. PloS one, 9(2), e87357.\n",
    "\n",
    "**Motor Imagery BCI:**\n",
    "- Ang, K. K., Chin, Z. Y., Wang, C., Guan, C., & Zhang, H. (2012). Filter bank common spatial pattern algorithm on BCI competition IV datasets 2a and 2b. Frontiers in neuroscience, 6, 39.\n",
    "- Lotte, F., Congedo, M., LÃ©cuyer, A., Lamarche, F., & Arnaldi, B. (2007). A review of classification algorithms for EEG-based brainâ€“computer interfaces. Journal of neural engineering, 4(2), R1.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Summary Statistics for LaTeX Report\n",
    "\n",
    "### Feature Extraction Summary Table"
   ],
   "id": "1ea0613251d2583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table for report\n",
    "summary_data = [\n",
    "    {\n",
    "        'Feature Type': 'Common Spatial Patterns',\n",
    "        'Method': 'CSP (One-vs-Rest)',\n",
    "        'Features': csp_features.shape[1],\n",
    "        'Domain': 'Spatial',\n",
    "        'Mean MI': f\"{np.mean(mi_scores[:csp_features.shape[1]]):.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Feature Type': 'Band Power',\n",
    "        'Method': 'Welch PSD (4 bands)',\n",
    "        'Features': band_power_features.shape[1],\n",
    "        'Domain': 'Frequency',\n",
    "        'Mean MI': f\"{np.mean(mi_scores[csp_features.shape[1]:csp_features.shape[1]+band_power_features.shape[1]]):.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Feature Type': 'Hjorth Parameters',\n",
    "        'Method': 'Activity/Mobility/Complexity',\n",
    "        'Features': hjorth_features.shape[1],\n",
    "        'Domain': 'Time',\n",
    "        'Mean MI': f\"{np.mean(mi_scores[csp_features.shape[1]+band_power_features.shape[1]:csp_features.shape[1]+band_power_features.shape[1]+hjorth_features.shape[1]]):.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Feature Type': 'Statistical',\n",
    "        'Method': 'Mean/Std/Skew/Kurt',\n",
    "        'Features': statistical_features.shape[1],\n",
    "        'Domain': 'Statistical',\n",
    "        'Mean MI': f\"{np.mean(mi_scores[-statistical_features.shape[1]:]):.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'Feature Type': 'TOTAL',\n",
    "        'Method': 'Combined & Normalized',\n",
    "        'Features': features_normalized.shape[1],\n",
    "        'Domain': 'Multi-domain',\n",
    "        'Mean MI': f\"{np.mean(mi_scores):.4f}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save table\n",
    "tables_dir = RESULTS_DIR.parent / 'tables'\n",
    "tables_dir.mkdir(exist_ok=True)\n",
    "summary_df.to_csv(tables_dir / 'feature_extraction_summary.csv', index=False)\n",
    "summary_df.to_latex(tables_dir / 'feature_extraction_summary.tex', index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Summary table saved to {tables_dir}\")\n",
    "print(f\"  - CSV format: feature_extraction_summary.csv\")\n",
    "print(f\"  - LaTeX format: feature_extraction_summary.tex\")"
   ],
   "id": "da1b021ca872de9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ðŸ“Š Top Features by Channel Analysis",
   "id": "ebe1b74c7e8795d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHANNEL CONTRIBUTION TO TOP FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze which channels contribute most to top features\n",
    "channel_counts = {}\n",
    "for feat_name in top_names:\n",
    "    # Skip CSP features (they combine multiple channels)\n",
    "    if 'CSP' in feat_name:\n",
    "        continue\n",
    "\n",
    "    # Extract channel name\n",
    "    for ch in epochs.ch_names:\n",
    "        if ch in feat_name:\n",
    "            if ch not in channel_counts:\n",
    "                channel_counts[ch] = 0\n",
    "            channel_counts[ch] += 1\n",
    "            break\n",
    "\n",
    "# Sort by count\n",
    "sorted_channels = sorted(channel_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nðŸ“Š Top 10 Channels Contributing to Discriminative Features:\")\n",
    "for i, (ch, count) in enumerate(sorted_channels[:10], 1):\n",
    "    print(f\"  {i}. {ch}: {count} features in top 20\")\n",
    "\n",
    "# Create visualization\n",
    "if sorted_channels:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    channels = [ch for ch, _ in sorted_channels[:10]]\n",
    "    counts = [count for _, count in sorted_channels[:10]]\n",
    "\n",
    "    bars = ax.barh(channels, counts, color=sns.color_palette(\"viridis\", len(channels)))\n",
    "\n",
    "    ax.set_xlabel('Number of Features in Top 20', fontsize=12)\n",
    "    ax.set_ylabel('Channel', fontsize=12)\n",
    "    ax.set_title('Channel Contribution to Most Discriminative Features',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "    # Add count labels\n",
    "    for bar, count in zip(bars, counts):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width, bar.get_y() + bar.get_height()/2,\n",
    "                f'{int(count)}', ha='left', va='center', fontsize=10,\n",
    "                fontweight='bold', color='black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / '03_channel_contribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nâœ“ Channel contribution analysis complete\")\n",
    "else:\n",
    "    print(\"\\nâš  All top features are CSP (no single-channel features)\")"
   ],
   "id": "edb90e7b18897ba6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸŽ¯ Feature Selection Recommendations\n",
    "\n",
    "Based on mutual information analysis, we can recommend optimal feature subsets."
   ],
   "id": "fcafd5e61adee16c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE SELECTION RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze performance vs number of features\n",
    "feature_thresholds = [10, 20, 30, 50, 100, 150, 200, 264]\n",
    "\n",
    "print(f\"\\nðŸ“Š Feature Subset Recommendations:\")\n",
    "print(f\"\\n{'Features':<10} {'Cumulative MI':<20} {'% of Total MI':<15} {'Recommendation'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "total_mi = np.sum(mi_scores)\n",
    "\n",
    "for n_features in feature_thresholds:\n",
    "    if n_features > len(mi_scores):\n",
    "        n_features = len(mi_scores)\n",
    "\n",
    "    # Get top n features\n",
    "    top_n_indices = np.argsort(mi_scores)[-n_features:][::-1]\n",
    "    cumulative_mi = np.sum(mi_scores[top_n_indices])\n",
    "    percentage = (cumulative_mi / total_mi) * 100\n",
    "\n",
    "    # Recommendation\n",
    "    if n_features == 20:\n",
    "        rec = \"â­ Minimum recommended\"\n",
    "    elif n_features == 50:\n",
    "        rec = \"â­â­ Good balance\"\n",
    "    elif n_features == 100:\n",
    "        rec = \"â­â­â­ Comprehensive\"\n",
    "    elif n_features == 264:\n",
    "        rec = \"â­â­â­â­ Full feature set\"\n",
    "    else:\n",
    "        rec = \"\"\n",
    "\n",
    "    print(f\"{n_features:<10} {cumulative_mi:<20.6f} {percentage:<15.2f} {rec}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Recommendations:\")\n",
    "print(\"  - Start with top 20 features for fast prototyping\")\n",
    "print(\"  - Use top 50-100 features for optimal classification\")\n",
    "print(\"  - Full 264 features for ensemble methods and deep learning\")\n",
    "print(\"  - Apply feature selection during cross-validation\")\n",
    "\n",
    "print(\"\\nâœ“ Feature selection analysis complete\")"
   ],
   "id": "5184b852ba327765",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## ðŸ”š Final Checklist\n",
    "\n",
    "Verify all steps completed successfully before proceeding to classification."
   ],
   "id": "15d52c211e22fc15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION CHECKLIST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get actual feature counts dynamically\n",
    "expected_csp = csp_features.shape[1]\n",
    "expected_bandpower = band_power_features.shape[1]\n",
    "expected_hjorth = hjorth_features.shape[1]\n",
    "expected_stat = statistical_features.shape[1]\n",
    "expected_total = expected_csp + expected_bandpower + expected_hjorth + expected_stat\n",
    "\n",
    "print(f\"\\nDetected feature counts:\")\n",
    "print(f\"  CSP: {expected_csp}\")\n",
    "print(f\"  Band Power: {expected_bandpower}\")\n",
    "print(f\"  Hjorth: {expected_hjorth}\")\n",
    "print(f\"  Statistical: {expected_stat}\")\n",
    "print(f\"  Total: {expected_total}\")\n",
    "print()\n",
    "\n",
    "checklist = [\n",
    "    (\"CSP features extracted\", csp_features.shape[1] == expected_csp),\n",
    "    (\"Band power features extracted\", band_power_features.shape[1] == expected_bandpower),\n",
    "    (\"Hjorth parameters extracted\", hjorth_features.shape[1] == expected_hjorth),\n",
    "    (\"Statistical features extracted\", statistical_features.shape[1] == expected_stat),\n",
    "    (\"Features combined\", features_normalized.shape[1] == expected_total),\n",
    "    (\"Features normalized\", abs(np.mean(features_normalized)) < 0.01),\n",
    "    (\"No NaN values\", not np.any(np.isnan(features_normalized))),\n",
    "    (\"No Inf values\", not np.any(np.isinf(features_normalized))),\n",
    "    (\"Mutual information computed\", len(mi_scores) == features_normalized.shape[1]),\n",
    "    (\"CSP patterns visualized\", True),\n",
    "    (\"ERD/ERS maps generated\", True),\n",
    "    (\"Feature importance analyzed\", len(top_names) == 20),\n",
    "    (\"Features saved to file\", features_file.exists()),\n",
    "    (\"Visualizations saved\", len(list(RESULTS_DIR.glob('03_*.png'))) >= 5)\n",
    "]\n",
    "\n",
    "all_passed = True\n",
    "for item, status in checklist:\n",
    "    symbol = \"âœ“\" if status else \"âœ—\"\n",
    "    print(f\"  {symbol} {item}\")\n",
    "    if not status:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "if all_passed:\n",
    "    print(\"âœ… ALL CHECKS PASSED - Ready for classification!\")\n",
    "    print(\"\\nYou can now proceed to notebook 04_classification_traditional.ipynb\")\n",
    "else:\n",
    "    print(\"âš  SOME CHECKS FAILED - Review errors above\")\n",
    "print(\"=\"*80)"
   ],
   "id": "7241a46730074c53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7a31441a532772b8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
