{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook 04: Traditional Machine Learning Classification\n",
    "\n",
    "## Motor Imagery Classification using BCI Competition IV Dataset 2a\n",
    "\n",
    "**Author:** Rahma Aroua"
   ],
   "id": "d4de8fa46d8b75f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìã Notebook Overview\n",
    "\n",
    "In this notebook, we implement and compare traditional machine learning classifiers for motor imagery classification:\n",
    "\n",
    "1. **Linear Discriminant Analysis (LDA)** - Baseline classifier\n",
    "2. **Support Vector Machine (SVM)** - With RBF kernel\n",
    "3. **Random Forest** - Ensemble method\n",
    "4. **k-Nearest Neighbors (k-NN)** - Instance-based learning\n",
    "\n",
    "We'll evaluate each model using:\n",
    "- Cross-validation\n",
    "- Confusion matrices\n",
    "- Multiple performance metrics (accuracy, kappa, F1-score)\n",
    "- Statistical significance tests"
   ],
   "id": "9833ff0e3b693f5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîß Setup and Imports",
   "id": "e3d4f6fff4c8ff8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Our custom utilities\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.data_loader import load_subject_data, load_processed_data\n",
    "from utils.models import (train_lda_classifier, train_svm_classifier,\n",
    "                          train_random_forest, train_knn_classifier,\n",
    "                          evaluate_model, cross_validate_model, save_model)\n",
    "from utils.evaluation import (compute_metrics, cross_validate_subject,\n",
    "                              plot_confusion_matrix, compare_models,\n",
    "                              compute_information_transfer_rate,\n",
    "                              statistical_comparison)\n",
    "from utils.visualization import plot_feature_importance\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì All imports successful!\")"
   ],
   "id": "5b19671ec08a6f06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìä Load Preprocessed Data and Features",
   "id": "2bfb95adffacb661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "DATA_DIR = Path('../data/processed/')\n",
    "FEATURES_DIR = Path('../data/features/')\n",
    "FIGURES_DIR = Path('../results/figures')\n",
    "CLASSIFICATION_DIR = Path('../results/classification_results')\n",
    "\n",
    "\n",
    "# Load features for Subject A01\n",
    "subject_id = 'A01T'\n",
    "print(f\"Loading features for {subject_id}...\")\n",
    "\n",
    "# Load extracted features (from notebook 03)\n",
    "features_data = load_processed_data(FEATURES_DIR / f'{subject_id}_features.pkl')\n",
    "\n",
    "X = features_data['features']  # (n_trials, n_features)\n",
    "y = features_data['labels']     # (n_trials,)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ],
   "id": "c7f8d8170e649bde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üîÄ Train-Test Split",
   "id": "76a63ed27995b1c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split data with stratification to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTrain class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "# Feature standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\n‚úì Data split and standardization complete!\")"
   ],
   "id": "5db785e85a8418b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üéØ Model 1: Linear Discriminant Analysis (LDA)\n",
    "LDA is a simple yet effective baseline classifier for BCI applications. It finds linear combinations of features that best separate classes."
   ],
   "id": "43e1372779385fa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Training LDA Classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train LDA\n",
    "lda_model = train_lda_classifier(X_train_scaled, y_train, solver='svd')\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_lda = lda_model.predict(X_test_scaled)\n",
    "lda_metrics = compute_metrics(y_test, y_pred_lda)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"  Accuracy: {lda_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Cohen's Kappa: {lda_metrics['cohen_kappa']:.4f}\")\n",
    "print(f\"  Macro F1-Score: {lda_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "# Cross-validation on full dataset\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda_cv_results = cross_validate_subject(\n",
    "    LinearDiscriminantAnalysis(solver='svd'),\n",
    "    X, y, cv=5\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig_lda = plot_confusion_matrix(\n",
    "    lda_metrics['confusion_matrix'],\n",
    "    class_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "    normalize=True\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / '04_lda_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(lda_model, '../models/traditional/lda_A01.pkl')"
   ],
   "id": "9d590f131fc9f7d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üéØ Model 2: Support Vector Machine (SVM)\n",
    "SVM with RBF kernel can capture non-linear relationships in the feature space."
   ],
   "id": "290cceb660a0b42a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training SVM Classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train SVM with RBF kernel\n",
    "svm_model = train_svm_classifier(\n",
    "    X_train_scaled, y_train,\n",
    "    kernel='rbf',\n",
    "    C=1.0,\n",
    "    gamma='scale'\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "svm_metrics = compute_metrics(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"  Accuracy: {svm_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Cohen's Kappa: {svm_metrics['cohen_kappa']:.4f}\")\n",
    "print(f\"  Macro F1-Score: {svm_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm_cv_results = cross_validate_subject(\n",
    "    SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42),\n",
    "    X, y, cv=5\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig_svm = plot_confusion_matrix(\n",
    "    svm_metrics['confusion_matrix'],\n",
    "    class_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "    normalize=True\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / '04_svm_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(svm_model, '../models/traditional/svm_A01.pkl')"
   ],
   "id": "771407c022c4251",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üéØ Model 3: Random Forest\n",
    "\n",
    "Random Forest is an ensemble method that can handle high-dimensional feature spaces."
   ],
   "id": "439ca688291a0034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Random Forest Classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = train_random_forest(\n",
    "    X_train_scaled, y_train,\n",
    "    n_estimators=100,\n",
    "    max_depth=None\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "rf_metrics = compute_metrics(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"  Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Cohen's Kappa: {rf_metrics['cohen_kappa']:.4f}\")\n",
    "print(f\"  Macro F1-Score: {rf_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = rf_model.feature_importances_\n",
    "top_features_idx = np.argsort(feature_importance)[-20:]  # Top 20\n",
    "top_features = feature_importance[top_features_idx]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(20), top_features)\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.ylabel('Feature Index', fontsize=12)\n",
    "plt.title('Top 20 Most Important Features (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / '04_rf_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_cv_results = cross_validate_subject(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    X, y, cv=5\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig_rf = plot_confusion_matrix(\n",
    "    rf_metrics['confusion_matrix'],\n",
    "    class_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "    normalize=True\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / '04_rf_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(rf_model, '../models/traditional/rf_A01.pkl')"
   ],
   "id": "e3dc862651f3a389",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üéØ Model 4: k-Nearest Neighbors (k-NN)",
   "id": "fa8dc75c2c7b4778"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training k-NN Classifier\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train k-NN\n",
    "knn_model = train_knn_classifier(X_train_scaled, y_train, n_neighbors=5)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "knn_metrics = compute_metrics(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"\\nüìä Test Set Performance:\")\n",
    "print(f\"  Accuracy: {knn_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Cohen's Kappa: {knn_metrics['cohen_kappa']:.4f}\")\n",
    "print(f\"  Macro F1-Score: {knn_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "# Cross-validation\n",
    "print(f\"\\nüîÑ Cross-Validation (5-fold):\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_cv_results = cross_validate_subject(\n",
    "    KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    X, y, cv=5\n",
    ")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig_knn = plot_confusion_matrix(\n",
    "    knn_metrics['confusion_matrix'],\n",
    "    class_names=['Left Hand', 'Right Hand', 'Feet', 'Tongue'],\n",
    "    normalize=True\n",
    ")\n",
    "plt.savefig(FIGURES_DIR / '04_knn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "save_model(knn_model, '../models/traditional/knn_A01.pkl')"
   ],
   "id": "6d4e6b795d852413",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìä Model Comparison",
   "id": "1ccd98ad51d0cddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile all results\n",
    "all_results = {\n",
    "    'LDA': lda_cv_results,\n",
    "    'SVM (RBF)': svm_cv_results,\n",
    "    'Random Forest': rf_cv_results,\n",
    "    'k-NN': knn_cv_results\n",
    "}\n",
    "\n",
    "# Compute ITR for each model\n",
    "for model_name, results in all_results.items():\n",
    "    itr = compute_information_transfer_rate(\n",
    "        accuracy=results['accuracy_mean'],\n",
    "        n_classes=4,\n",
    "        trial_duration=4.0\n",
    "    )\n",
    "    results['itr'] = itr\n",
    "\n",
    "# Create comparison plot\n",
    "fig_comparison = compare_models(all_results, metric='accuracy')\n",
    "plt.savefig(FIGURES_DIR / '04_model_comparison_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary table\n",
    "from utils.evaluation import create_performance_summary\n",
    "summary_df = create_performance_summary(\n",
    "    all_results,\n",
    "    save_path=CLASSIFICATION_DIR / 'performance_summary.csv'  # Changed from RESULTS_DIR\n",
    ")"
   ],
   "id": "75601300e445a923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üìà Statistical Significance Testing",
   "id": "6edbf31c1206f0c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## üìà Statistical Significance Testing\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICAL SIGNIFICANCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Compare Best Model (RF) vs Baseline (LDA)\n",
    "print(\"\\n1. Random Forest vs LDA (Best vs Baseline)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "lda_scores = np.array(lda_cv_results['fold_accuracies'])\n",
    "rf_scores = np.array(rf_cv_results['fold_accuracies'])\n",
    "\n",
    "stat_rf_lda = statistical_comparison(rf_scores, lda_scores, test='wilcoxon')\n",
    "\n",
    "print(f\"Mean Accuracy: RF={rf_scores.mean():.4f}, LDA={lda_scores.mean():.4f}\")\n",
    "print(f\"Improvement: {(rf_scores.mean() - lda_scores.mean()):.4f} ({((rf_scores.mean() - lda_scores.mean())/lda_scores.mean()*100):.1f}%)\")\n",
    "print(f\"p-value: {stat_rf_lda['p_value']:.4f}\")\n",
    "print(f\"Significant: {'Yes ‚úì' if stat_rf_lda['significant'] else 'No ‚úó'}\")\n",
    "\n",
    "# 2. Compare RF vs SVM (Best vs Most Stable)\n",
    "print(\"\\n2. Random Forest vs SVM (Best vs Most Stable)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "svm_scores = np.array(svm_cv_results['fold_accuracies'])\n",
    "\n",
    "stat_rf_svm = statistical_comparison(rf_scores, svm_scores, test='wilcoxon')\n",
    "\n",
    "print(f\"Mean Accuracy: RF={rf_scores.mean():.4f}, SVM={svm_scores.mean():.4f}\")\n",
    "print(f\"Std Dev: RF={rf_scores.std():.4f}, SVM={svm_scores.std():.4f}\")\n",
    "print(f\"Improvement: {(rf_scores.mean() - svm_scores.mean()):.4f} ({((rf_scores.mean() - svm_scores.mean())/svm_scores.mean()*100):.1f}%)\")\n",
    "print(f\"p-value: {stat_rf_svm['p_value']:.4f}\")\n",
    "print(f\"Significant: {'Yes ‚úì' if stat_rf_svm['significant'] else 'No ‚úó'}\")\n",
    "\n",
    "# 3. Compare SVM vs LDA (Your original comparison)\n",
    "print(\"\\n3. SVM vs LDA (Stable Model vs Baseline)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "stat_svm_lda = statistical_comparison(svm_scores, lda_scores, test='wilcoxon')\n",
    "\n",
    "print(f\"Mean Accuracy: SVM={svm_scores.mean():.4f}, LDA={lda_scores.mean():.4f}\")\n",
    "print(f\"Improvement: {(svm_scores.mean() - lda_scores.mean()):.4f} ({((svm_scores.mean() - lda_scores.mean())/lda_scores.mean()*100):.1f}%)\")\n",
    "print(f\"p-value: {stat_svm_lda['p_value']:.4f}\")\n",
    "print(f\"Significant: {'Yes ‚úì' if stat_svm_lda['significant'] else 'No ‚úó'}\")\n",
    "\n",
    "# 4. Effect Size Analysis (Cohen's d)\n",
    "print(\"\\n4. Effect Size Analysis (Cohen's d)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    \"\"\"Calculate Cohen's d for effect size\"\"\"\n",
    "    nx, ny = len(x), len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof)\n",
    "\n",
    "d_rf_lda = cohens_d(rf_scores, lda_scores)\n",
    "d_rf_svm = cohens_d(rf_scores, svm_scores)\n",
    "d_svm_lda = cohens_d(svm_scores, lda_scores)\n",
    "\n",
    "print(f\"RF vs LDA: d = {d_rf_lda:.3f} ({'Large' if abs(d_rf_lda) > 0.8 else 'Medium' if abs(d_rf_lda) > 0.5 else 'Small'})\")\n",
    "print(f\"RF vs SVM: d = {d_rf_svm:.3f} ({'Large' if abs(d_rf_svm) > 0.8 else 'Medium' if abs(d_rf_svm) > 0.5 else 'Small'})\")\n",
    "print(f\"SVM vs LDA: d = {d_svm_lda:.3f} ({'Large' if abs(d_svm_lda) > 0.8 else 'Medium' if abs(d_svm_lda) > 0.5 else 'Small'})\")\n",
    "\n",
    "# 5. Interpretation\n",
    "print(\"\\n5. Interpretation\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Cohen's d interpretation:\")\n",
    "print(\"  Small effect: |d| = 0.2-0.5\")\n",
    "print(\"  Medium effect: |d| = 0.5-0.8\")\n",
    "print(\"  Large effect: |d| > 0.8\")\n",
    "print(\"\\nNote: With 5-fold CV, statistical power is limited.\")\n",
    "print(\"      Non-significant results may become significant with more folds or subjects.\")\n",
    "\n",
    "# 6. Comprehensive Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Box plot comparison\n",
    "ax1 = axes[0]\n",
    "data_to_plot = [lda_scores, svm_scores, rf_scores]\n",
    "positions = [1, 2, 3]\n",
    "bp = ax1.boxplot(data_to_plot, positions=positions, widths=0.6,\n",
    "                 patch_artist=True, notch=True, showmeans=True)\n",
    "\n",
    "colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax1.set_xticklabels(['LDA', 'SVM', 'Random Forest'])\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Comparison (5-fold CV)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add significance brackets\n",
    "y_max = max(lda_scores.max(), svm_scores.max(), rf_scores.max())\n",
    "if stat_rf_lda['significant']:\n",
    "    ax1.plot([1, 3], [y_max + 0.03, y_max + 0.03], 'k-', lw=1.5)\n",
    "    ax1.text(2, y_max + 0.04, f\"p={stat_rf_lda['p_value']:.3f}*\",\n",
    "             ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Violin plot for distribution\n",
    "ax2 = axes[1]\n",
    "parts = ax2.violinplot(data_to_plot, positions=positions, widths=0.7,\n",
    "                       showmeans=True, showmedians=True)\n",
    "\n",
    "for pc, color in zip(parts['bodies'], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "ax2.set_xticklabels(['LDA', 'SVM', 'Random Forest'])\n",
    "ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Distribution of Cross-Validation Scores', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / '04_comprehensive_statistical_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 7. Summary Table\n",
    "print(\"\\n6. Statistical Summary Table\")\n",
    "print(\"=\"*60)\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Comparison': ['RF vs LDA', 'RF vs SVM', 'SVM vs LDA'],\n",
    "    'Mean Diff': [\n",
    "        rf_scores.mean() - lda_scores.mean(),\n",
    "        rf_scores.mean() - svm_scores.mean(),\n",
    "        svm_scores.mean() - lda_scores.mean()\n",
    "    ],\n",
    "    'p-value': [\n",
    "        stat_rf_lda['p_value'],\n",
    "        stat_rf_svm['p_value'],\n",
    "        stat_svm_lda['p_value']\n",
    "    ],\n",
    "    'Significant': [\n",
    "        'Yes' if stat_rf_lda['significant'] else 'No',\n",
    "        'Yes' if stat_rf_svm['significant'] else 'No',\n",
    "        'Yes' if stat_svm_lda['significant'] else 'No'\n",
    "    ],\n",
    "    'Effect Size': [d_rf_lda, d_rf_svm, d_svm_lda]\n",
    "})\n",
    "\n",
    "print(summary_stats.to_string(index=False))\n",
    "summary_stats.to_csv(CLASSIFICATION_DIR / 'statistical_comparison_summary.csv', index=False)\n",
    "print(f\"\\n‚úì Statistical summary saved to {CLASSIFICATION_DIR / 'statistical_comparison_summary.csv'}\")"
   ],
   "id": "a9022669a71cf9b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## üíæ Save All Results",
   "id": "50e92dff9d8ac45c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## üíæ Save Results\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Create comprehensive results package\n",
    "results_package = {\n",
    "    'subject_id': subject_id,\n",
    "    'models': {\n",
    "        'lda': {'model': lda_model, 'metrics': lda_metrics, 'cv': lda_cv_results},\n",
    "        'svm': {'model': svm_model, 'metrics': svm_metrics, 'cv': svm_cv_results},\n",
    "        'rf': {'model': rf_model, 'metrics': rf_metrics, 'cv': rf_cv_results},\n",
    "        'knn': {'model': knn_model, 'metrics': knn_metrics, 'cv': knn_cv_results},\n",
    "    },\n",
    "    'statistical_tests': {\n",
    "        'rf_vs_lda': stat_rf_lda,\n",
    "        'rf_vs_svm': stat_rf_svm,\n",
    "        'svm_vs_lda': stat_svm_lda\n",
    "    },\n",
    "    'scaler': scaler\n",
    "}\n",
    "\n",
    "# Save everything in one file\n",
    "with open(CLASSIFICATION_DIR / f'{subject_id}_classification_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results_package, f)\n",
    "\n",
    "# Save best model for deployment\n",
    "save_model(rf_model, '../models/traditional/best_model_A01.pkl')\n",
    "save_model(scaler, '../models/traditional/scaler_A01.pkl')\n",
    "\n",
    "print(f\"\\n‚úì All results saved to {CLASSIFICATION_DIR}/classification_results/\")\n",
    "print(f\"‚úì Best model (Random Forest) and scaler saved for deployment\")"
   ],
   "id": "d994dd791c87b19a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## üìù Key Findings\n",
    "\n",
    "### Performance Summary\n",
    "- **Best Model:** Random Forest achieved the highest accuracy (67.66% ¬± 7.11%)\n",
    "- **Runner-up:** SVM with RBF kernel (63.19% ¬± 2.77%) - more stable performance (lower std)\n",
    "- **Baseline:** LDA provides reasonable performance (48.20%) with lowest computational cost\n",
    "- **Instance-based:** k-NN shows moderate performance (59.33%) but requires storing all training data\n",
    "\n",
    "### Important Observations\n",
    "1. All models perform significantly above chance level (25% for 4-class problem)\n",
    "2. Random Forest shows highest accuracy but also highest variance (std=7.11%)\n",
    "3. SVM demonstrates most stable performance with lowest standard deviation (2.77%)\n",
    "4. The performance gap between LDA and ensemble methods suggests non-linear patterns in the data\n",
    "5. CSP features appear discriminative across all models (implied by above-chance performance)\n",
    "\n",
    "### Model-Specific Insights\n",
    "- **Random Forest**: Best accuracy but requires careful tuning to reduce variance\n",
    "- **SVM**: Good balance between performance (63.19%) and stability\n",
    "- **LDA**: Fast and interpretable but limited by linear decision boundary assumption\n",
    "- **k-NN**: Acceptable performance but memory-intensive and slow at prediction time\n",
    "\n",
    "### Statistical Validation\n",
    "- RF vs LDA shows practical improvement (19.5% relative gain)\n",
    "- SVM vs LDA: p=0.0625 (marginally non-significant), but Cohen's d suggests meaningful difference\n",
    "- Limited statistical power due to 5-fold CV; larger validation recommended\n",
    "- Effect sizes indicate RF and SVM offer substantial improvements over LDA baseline\n",
    "\n",
    "---\n",
    "## üéì Conclusion\n",
    "\n",
    "This notebook demonstrated traditional machine learning approaches for motor imagery classification using BCI Competition IV Dataset 2a (Subject A01).\n",
    "\n",
    "**Key Results:**\n",
    "- **Best Performer**: Random Forest achieved **67.66% accuracy** with **Cohen's Kappa = 0.57**, though with higher variance\n",
    "- **Most Stable**: SVM (RBF) achieved **63.19% accuracy** with **Cohen's Kappa = 0.51** and lowest standard deviation\n",
    "- **Information Transfer Rate**: Random Forest reached **8.69 bits/min**, suitable for practical BCI applications\n",
    "\n",
    "**Performance Context:**\n",
    "- All models significantly exceed chance level (25%)\n",
    "- Results are consistent with typical subject-dependent motor imagery classification\n",
    "- The 48-68% accuracy range aligns with published benchmarks for 4-class MI tasks\n",
    "\n",
    "**Trade-offs Identified:**\n",
    "- **Accuracy vs Stability**: RF highest accuracy but unstable; SVM more reliable\n",
    "- **Complexity vs Performance**: LDA simplest but limited; ensemble methods better but computationally expensive\n",
    "- **Practical Considerations**: SVM offers best balance for real-time BCI applications\n",
    "\n",
    "**Next Notebook:** [05_classification_deep_learning.ipynb](05_classification_deep_learning.ipynb)"
   ],
   "id": "c6c8e25343f91961"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "26560978134ada2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a63ff894c7f333c5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
